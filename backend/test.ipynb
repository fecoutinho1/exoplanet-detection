{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77a41368",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loading model components...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EXOPLANET DETECTOR - LOCAL TEST\n",
      "============================================================\n",
      "\n",
      "1. Initializing Exoplanet Detector...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Model loaded from: exoplanet_detector_model.pkl\n",
      "INFO:__main__:Scaler loaded from: exoplanet_scaler.pkl\n",
      "INFO:__main__:Features loaded from: exoplanet_features.pkl\n",
      "INFO:__main__:All components loaded successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model loaded successfully!\n",
      "   Features: 15\n",
      "   Model type: XGBoost\n",
      "\n",
      "2. Loading CSV file: output_15_linhas.csv\n",
      "âœ… Loaded 15 rows from CSV\n",
      "\n",
      "3. Checking required features...\n",
      "âœ… All required features present!\n",
      "\n",
      "4. Processing 15 candidates...\n",
      "------------------------------------------------------------\n",
      "Row  1: ðŸŸ¢ EXOPLANET (100.0%) - K00752.01 (Kepler-227 b)\n",
      "Row  2: ðŸŸ¢ EXOPLANET (100.0%) - K00752.02 (Kepler-227 c)\n",
      "Row  3: ðŸŸ¢ EXOPLANET (99.5%) - K00753.01 (nan)\n",
      "Row  4: ðŸ”´ FALSE POSITIVE (99.9%) - K00754.01 (nan)\n",
      "Row  5: ðŸŸ¢ EXOPLANET (100.0%) - K00755.01 (Kepler-664 b)\n",
      "Row  6: ðŸŸ¢ EXOPLANET (100.0%) - K00756.01 (Kepler-228 d)\n",
      "Row  7: ðŸŸ¢ EXOPLANET (99.9%) - K00756.02 (Kepler-228 c)\n",
      "Row  8: ðŸŸ¢ EXOPLANET (99.9%) - K00756.03 (Kepler-228 b)\n",
      "Row  9: ðŸ”´ FALSE POSITIVE (100.0%) - K00114.01 (nan)\n",
      "Row 10: ðŸŸ¢ EXOPLANET (100.0%) - K00757.01 (Kepler-229 c)\n",
      "Row 11: ðŸŸ¢ EXOPLANET (99.9%) - K00001.01 (Kepler-1 b)\n",
      "Row 12: ðŸŸ¢ EXOPLANET (97.1%) - K00002.01 (Kepler-2 b)\n",
      "Row 13: ðŸŸ¢ EXOPLANET (100.0%) - K00010.01 (Kepler-8 b)\n",
      "Row 14: ðŸŸ¢ EXOPLANET (100.0%) - K00112.02 (Kepler-466 c)\n",
      "Row 15: ðŸ”´ FALSE POSITIVE (99.9%) - K00742.01 (nan)\n",
      "\n",
      "============================================================\n",
      "ANALYSIS SUMMARY\n",
      "============================================================\n",
      "Total rows processed: 15\n",
      "Exoplanets detected: 12\n",
      "False positives: 3\n",
      "Success rate: 100.0%\n",
      "\n",
      "ðŸŸ¢ EXOPLANETS FOUND:\n",
      "  - Row 1: K00752.01 (Kepler-227 b) - 100.0% confidence\n",
      "  - Row 2: K00752.02 (Kepler-227 c) - 100.0% confidence\n",
      "  - Row 3: K00753.01 (nan) - 99.5% confidence\n",
      "  - Row 5: K00755.01 (Kepler-664 b) - 100.0% confidence\n",
      "  - Row 6: K00756.01 (Kepler-228 d) - 100.0% confidence\n",
      "  - Row 7: K00756.02 (Kepler-228 c) - 99.9% confidence\n",
      "  - Row 8: K00756.03 (Kepler-228 b) - 99.9% confidence\n",
      "  - Row 10: K00757.01 (Kepler-229 c) - 100.0% confidence\n",
      "  - Row 11: K00001.01 (Kepler-1 b) - 99.9% confidence\n",
      "  - Row 12: K00002.01 (Kepler-2 b) - 97.1% confidence\n",
      "  - Row 13: K00010.01 (Kepler-8 b) - 100.0% confidence\n",
      "  - Row 14: K00112.02 (Kepler-466 c) - 100.0% confidence\n",
      "\n",
      "âœ… Test completed successfully!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Exoplanet Detection Model\n",
    "=========================\n",
    "\n",
    "Exoplanet classification system using Machine Learning.\n",
    "Implemented in Object-Oriented Programming for production use.\n",
    "\n",
    "This system is specifically designed for Kepler Space Telescope data.\n",
    "For multi-mission support and generalization details, see:\n",
    "- MISSION_GENERALIZATION.md\n",
    "- TECHNICAL_ARCHITECTURE.md\n",
    "\n",
    "Author: Felipe Coutinho\n",
    "NASA Space Apps Challenge 2025\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import pickle\n",
    "from typing import Dict, List, Optional, Union, Tuple\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class ExoplanetDetector:\n",
    "    \"\"\"\n",
    "    Main class for exoplanet detection.\n",
    "    \n",
    "    This class encapsulates the entire process of classifying exoplanet\n",
    "    candidates using a trained XGBoost model.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_path: str = \"exoplanet_detector_model.pkl\",\n",
    "                 scaler_path: str = \"exoplanet_scaler.pkl\",\n",
    "                 features_path: str = \"exoplanet_features.pkl\"):\n",
    "        \"\"\"\n",
    "        Initialize the exoplanet detector.\n",
    "        \n",
    "        Args:\n",
    "            model_path: Path to the trained model file\n",
    "            scaler_path: Path to the scaler file\n",
    "            features_path: Path to the features list file\n",
    "        \"\"\"\n",
    "        self.model_path = model_path\n",
    "        self.scaler_path = scaler_path\n",
    "        self.features_path = features_path\n",
    "        \n",
    "        self.model = None\n",
    "        self.scaler = None\n",
    "        self.features = None\n",
    "        self.is_loaded = False\n",
    "        \n",
    "        # Load components automatically\n",
    "        self.load_components()\n",
    "    \n",
    "    def load_components(self) -> bool:\n",
    "        \"\"\"\n",
    "        Load the model, scaler and required features.\n",
    "        \n",
    "        Returns:\n",
    "            bool: True if loaded successfully, False otherwise\n",
    "        \"\"\"\n",
    "        try:\n",
    "            logger.info(\"Loading model components...\")\n",
    "            \n",
    "            # Load XGBoost model\n",
    "            self.model = joblib.load(self.model_path)\n",
    "            logger.info(f\"Model loaded from: {self.model_path}\")\n",
    "            \n",
    "            # Load scaler\n",
    "            self.scaler = joblib.load(self.scaler_path)\n",
    "            logger.info(f\"Scaler loaded from: {self.scaler_path}\")\n",
    "            \n",
    "            # Load features list\n",
    "            with open(self.features_path, 'rb') as f:\n",
    "                self.features = pickle.load(f)\n",
    "            logger.info(f\"Features loaded from: {self.features_path}\")\n",
    "            \n",
    "            self.is_loaded = True\n",
    "            logger.info(\"All components loaded successfully\")\n",
    "            return True\n",
    "            \n",
    "        except FileNotFoundError as e:\n",
    "            logger.error(f\"File not found: {e}\")\n",
    "            return False\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading components: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def validate_input(self, data: Dict) -> Tuple[bool, List[str]]:\n",
    "        \"\"\"\n",
    "        Validate if input data contains all required features.\n",
    "        \n",
    "        Args:\n",
    "            data: Dictionary with candidate data\n",
    "            \n",
    "        Returns:\n",
    "            Tuple[bool, List[str]]: (is_valid, error_list)\n",
    "        \"\"\"\n",
    "        if not isinstance(data, dict):\n",
    "            return False, [\"Data must be a dictionary\"]\n",
    "        \n",
    "        if not self.features:\n",
    "            return False, [\"Features not loaded\"]\n",
    "        \n",
    "        missing_features = set(self.features) - set(data.keys())\n",
    "        if missing_features:\n",
    "            return False, [f\"Missing features: {list(missing_features)}\"]\n",
    "        \n",
    "        return True, []\n",
    "    \n",
    "    def preprocess_data(self, data: Dict) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Preprocess candidate data for classification.\n",
    "        \n",
    "        Args:\n",
    "            data: Dictionary with candidate data\n",
    "            \n",
    "        Returns:\n",
    "            np.ndarray: Preprocessed and normalized data\n",
    "        \"\"\"\n",
    "        # Convert to DataFrame\n",
    "        df = pd.DataFrame([data])\n",
    "        \n",
    "        # Select only required features\n",
    "        X = df[self.features].copy()\n",
    "        \n",
    "        # Handle missing values\n",
    "        for column in X.columns:\n",
    "            if X[column].isnull().any():\n",
    "                median_value = X[column].median()\n",
    "                X[column] = X[column].fillna(median_value)\n",
    "                logger.warning(f\"Missing value filled in {column}: {median_value}\")\n",
    "        \n",
    "        # Normalize data\n",
    "        X_normalized = self.scaler.transform(X)\n",
    "        \n",
    "        return X_normalized\n",
    "    \n",
    "    def predict(self, data: Dict) -> Dict:\n",
    "        \"\"\"\n",
    "        MAIN FUNCTION: Classify exoplanet candidate.\n",
    "        \n",
    "        This is the main entry point for the API. It receives candidate data\n",
    "        and returns the classification result.\n",
    "        \n",
    "        Args:\n",
    "            data: Dictionary with candidate data containing all required features:\n",
    "                  - kepid: Star ID\n",
    "                  - koi_score: Confidence score (0-1)\n",
    "                  - koi_fpflag_nt: Not transit flag (0/1)\n",
    "                  - koi_fpflag_ss: Secondary star flag (0/1)\n",
    "                  - koi_fpflag_co: Contamination flag (0/1)\n",
    "                  - koi_fpflag_ec: Eclipse flag (0/1)\n",
    "                  - koi_period: Orbital period (days)\n",
    "                  - koi_time0bk: Reference time\n",
    "                  - koi_duration: Transit duration (hours)\n",
    "                  - koi_depth: Transit depth\n",
    "                  - koi_prad: Planet radius (Earth units)\n",
    "                  - koi_srad: Star radius (Solar units)\n",
    "                  - koi_steff: Star temperature (Kelvin)\n",
    "                  - koi_slogg: Surface gravity log\n",
    "                  - koi_kepmag: Kepler magnitude\n",
    "                  - koi_model_snr: Signal-to-noise ratio\n",
    "            \n",
    "        Returns:\n",
    "            Dict: Classification result with prediction, confidence, and explanation\n",
    "        \"\"\"\n",
    "        if not self.is_loaded:\n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"error\": \"Model not loaded\",\n",
    "                \"prediction\": None\n",
    "            }\n",
    "        \n",
    "        # Validate input\n",
    "        is_valid, errors = self.validate_input(data)\n",
    "        if not is_valid:\n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"error\": \"; \".join(errors),\n",
    "                \"prediction\": None\n",
    "            }\n",
    "        \n",
    "        try:\n",
    "            # Preprocess data\n",
    "            X_processed = self.preprocess_data(data)\n",
    "            \n",
    "            # Make prediction\n",
    "            prediction = self.model.predict(X_processed)[0]\n",
    "            probabilities = self.model.predict_proba(X_processed)[0]\n",
    "            \n",
    "            # Calculate confidence\n",
    "            confidence = max(probabilities) * 100\n",
    "            \n",
    "            # Interpret result\n",
    "            if prediction == 1:\n",
    "                result_text = \"EXOPLANET DETECTED\"\n",
    "                explanation = f\"Candidate classified as exoplanet with {confidence:.1f}% confidence\"\n",
    "            else:\n",
    "                result_text = \"NOT AN EXOPLANET\"\n",
    "                explanation = f\"Candidate classified as false positive with {confidence:.1f}% confidence\"\n",
    "            \n",
    "            return {\n",
    "                \"success\": True,\n",
    "                \"prediction\": int(prediction),\n",
    "                \"prediction_text\": result_text,\n",
    "                \"probability_exoplanet\": float(probabilities[1]),\n",
    "                \"probability_false_positive\": float(probabilities[0]),\n",
    "                \"confidence\": float(confidence),\n",
    "                \"explanation\": explanation,\n",
    "                \"features_used\": self.features\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error during prediction: {e}\")\n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"error\": str(e),\n",
    "                \"prediction\": None\n",
    "            }\n",
    "    \n",
    "    def get_model_info(self) -> Dict:\n",
    "        \"\"\"\n",
    "        Return information about the loaded model.\n",
    "        \n",
    "        Returns:\n",
    "            Dict: Model information\n",
    "        \"\"\"\n",
    "        if not self.is_loaded:\n",
    "            return {\"loaded\": False}\n",
    "        \n",
    "        return {\n",
    "            \"loaded\": True,\n",
    "            \"model_type\": \"XGBoost\",\n",
    "            \"features_count\": len(self.features),\n",
    "            \"features\": self.features,\n",
    "            \"model_path\": self.model_path,\n",
    "            \"scaler_path\": self.scaler_path,\n",
    "            \"features_path\": self.features_path\n",
    "        }\n",
    "\n",
    "\n",
    "class ExoplanetAPI:\n",
    "    \"\"\"\n",
    "    Class for REST API interface.\n",
    "    \n",
    "    Provides methods for REST API integration and HTTP request processing.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, detector: ExoplanetDetector):\n",
    "        \"\"\"\n",
    "        Initialize the API interface.\n",
    "        \n",
    "        Args:\n",
    "            detector: ExoplanetDetector instance\n",
    "        \"\"\"\n",
    "        self.detector = detector\n",
    "    \n",
    "    def process_request(self, request_data: Dict) -> Dict:\n",
    "        \"\"\"\n",
    "        Process a classification request.\n",
    "        \n",
    "        Args:\n",
    "            request_data: HTTP request data\n",
    "            \n",
    "        Returns:\n",
    "            Dict: Formatted API response\n",
    "        \"\"\"\n",
    "        # Validate request structure\n",
    "        if \"candidate_data\" not in request_data:\n",
    "            return {\n",
    "                \"status\": \"error\",\n",
    "                \"message\": \"Field 'candidate_data' is required\",\n",
    "                \"data\": None\n",
    "            }\n",
    "        \n",
    "        candidate_data = request_data[\"candidate_data\"]\n",
    "        \n",
    "        # Make prediction\n",
    "        result = self.detector.predict(candidate_data)\n",
    "        \n",
    "        if result[\"success\"]:\n",
    "            return {\n",
    "                \"status\": \"success\",\n",
    "                \"message\": \"Classification completed successfully\",\n",
    "                \"data\": {\n",
    "                    \"prediction\": result[\"prediction\"],\n",
    "                    \"prediction_text\": result[\"prediction_text\"],\n",
    "                    \"confidence\": result[\"confidence\"],\n",
    "                    \"probabilities\": {\n",
    "                        \"exoplanet\": result[\"probability_exoplanet\"],\n",
    "                        \"false_positive\": result[\"probability_false_positive\"]\n",
    "                    },\n",
    "                    \"explanation\": result[\"explanation\"]\n",
    "                }\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                \"status\": \"error\",\n",
    "                \"message\": result[\"error\"],\n",
    "                \"data\": None\n",
    "            }\n",
    "    \n",
    "    def health_check(self) -> Dict:\n",
    "        \"\"\"\n",
    "        Check if the system is working.\n",
    "        \n",
    "        Returns:\n",
    "            Dict: System status\n",
    "        \"\"\"\n",
    "        model_info = self.detector.get_model_info()\n",
    "        \n",
    "        return {\n",
    "            \"status\": \"healthy\" if model_info[\"loaded\"] else \"unhealthy\",\n",
    "            \"model_loaded\": model_info[\"loaded\"],\n",
    "            \"timestamp\": pd.Timestamp.now().isoformat()\n",
    "        }\n",
    "\n",
    "\n",
    "def create_detector() -> ExoplanetDetector:\n",
    "    \"\"\"\n",
    "    Convenience function to create a detector.\n",
    "    \n",
    "    Returns:\n",
    "        ExoplanetDetector: Configured detector instance\n",
    "    \"\"\"\n",
    "    return ExoplanetDetector()\n",
    "\n",
    "\n",
    "def create_api() -> ExoplanetAPI:\n",
    "    \"\"\"\n",
    "    Convenience function to create an API.\n",
    "    \n",
    "    Returns:\n",
    "        ExoplanetAPI: Configured API instance\n",
    "    \"\"\"\n",
    "    detector = create_detector()\n",
    "    return ExoplanetAPI(detector)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\"\n",
    "    Test the exoplanet detector with output_15_linhas.csv\n",
    "    \"\"\"\n",
    "    import os\n",
    "    from pathlib import Path\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"EXOPLANET DETECTOR - LOCAL TEST\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Initialize detector\n",
    "    print(\"\\n1. Initializing Exoplanet Detector...\")\n",
    "    detector = ExoplanetDetector()\n",
    "    \n",
    "    if not detector.is_loaded:\n",
    "        print(\"âŒ ERROR: Model components not loaded!\")\n",
    "        print(\"Make sure these files exist:\")\n",
    "        print(\"- exoplanet_detector_model.pkl\")\n",
    "        print(\"- exoplanet_scaler.pkl\") \n",
    "        print(\"- exoplanet_features.pkl\")\n",
    "        exit(1)\n",
    "    \n",
    "    print(\"âœ… Model loaded successfully!\")\n",
    "    print(f\"   Features: {len(detector.features)}\")\n",
    "    print(f\"   Model type: XGBoost\")\n",
    "    \n",
    "    # Load CSV file\n",
    "    csv_file = \"output_15_linhas.csv\"\n",
    "    if not os.path.exists(csv_file):\n",
    "        print(f\"\\nâŒ ERROR: CSV file '{csv_file}' not found!\")\n",
    "        print(\"Make sure the file is in the same directory as this script.\")\n",
    "        exit(1)\n",
    "    \n",
    "    print(f\"\\n2. Loading CSV file: {csv_file}\")\n",
    "    df = pd.read_csv(csv_file)\n",
    "    print(f\"âœ… Loaded {len(df)} rows from CSV\")\n",
    "    \n",
    "    # Check required features\n",
    "    print(f\"\\n3. Checking required features...\")\n",
    "    missing_features = set(detector.features) - set(df.columns)\n",
    "    if missing_features:\n",
    "        print(f\"âŒ ERROR: Missing features: {list(missing_features)}\")\n",
    "        print(f\"Available features: {list(df.columns)}\")\n",
    "        exit(1)\n",
    "    \n",
    "    print(\"âœ… All required features present!\")\n",
    "    \n",
    "    # Process each row\n",
    "    print(f\"\\n4. Processing {len(df)} candidates...\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    results = []\n",
    "    exoplanet_count = 0\n",
    "    false_positive_count = 0\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        try:\n",
    "            # Extract required features\n",
    "            candidate_data = {feature: row[feature] for feature in detector.features}\n",
    "            \n",
    "            # Make prediction\n",
    "            result = detector.predict(candidate_data)\n",
    "            \n",
    "            if result[\"success\"]:\n",
    "                prediction = result[\"prediction\"]\n",
    "                confidence = result[\"confidence\"]\n",
    "                prediction_text = result[\"prediction_text\"]\n",
    "                \n",
    "                if prediction == 1:\n",
    "                    exoplanet_count += 1\n",
    "                    status = \"ðŸŸ¢ EXOPLANET\"\n",
    "                else:\n",
    "                    false_positive_count += 1\n",
    "                    status = \"ðŸ”´ FALSE POSITIVE\"\n",
    "                \n",
    "                # Get candidate info\n",
    "                kepid = row.get('kepid', 'N/A')\n",
    "                kepoi_name = row.get('kepoi_name', 'N/A')\n",
    "                kepler_name = row.get('kepler_name', 'N/A')\n",
    "                \n",
    "                print(f\"Row {index + 1:2d}: {status} ({confidence:.1f}%) - {kepoi_name} ({kepler_name})\")\n",
    "                \n",
    "                results.append({\n",
    "                    \"row_index\": index,\n",
    "                    \"kepid\": kepid,\n",
    "                    \"kepoi_name\": kepoi_name,\n",
    "                    \"kepler_name\": kepler_name,\n",
    "                    \"prediction\": prediction,\n",
    "                    \"confidence\": confidence,\n",
    "                    \"prediction_text\": prediction_text,\n",
    "                    \"success\": True\n",
    "                })\n",
    "            else:\n",
    "                print(f\"Row {index + 1:2d}: âŒ ERROR - {result['error']}\")\n",
    "                results.append({\n",
    "                    \"row_index\": index,\n",
    "                    \"success\": False,\n",
    "                    \"error\": result[\"error\"]\n",
    "                })\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Row {index + 1:2d}: âŒ EXCEPTION - {str(e)}\")\n",
    "            results.append({\n",
    "                \"row_index\": index,\n",
    "                \"success\": False,\n",
    "                \"error\": str(e)\n",
    "            })\n",
    "    \n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"ANALYSIS SUMMARY\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Total rows processed: {len(df)}\")\n",
    "    print(f\"Exoplanets detected: {exoplanet_count}\")\n",
    "    print(f\"False positives: {false_positive_count}\")\n",
    "    print(f\"Success rate: {len([r for r in results if r['success']]) / len(df) * 100:.1f}%\")\n",
    "    \n",
    "    # Show exoplanets found\n",
    "    if exoplanet_count > 0:\n",
    "        print(f\"\\nðŸŸ¢ EXOPLANETS FOUND:\")\n",
    "        for result in results:\n",
    "            if result[\"success\"] and result[\"prediction\"] == 1:\n",
    "                print(f\"  - Row {result['row_index'] + 1}: {result['kepoi_name']} ({result['kepler_name']}) - {result['confidence']:.1f}% confidence\")\n",
    "    \n",
    "    print(f\"\\nâœ… Test completed successfully!\")\n",
    "    print(\"=\" * 60)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
